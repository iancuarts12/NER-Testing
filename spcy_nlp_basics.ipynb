{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc070b11",
   "metadata": {},
   "source": [
    "Tokenization, POS Tagging, Parsing and NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ba79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.17.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.9/60.9 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adrian\\miniconda3\\envs\\myenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/13.9 MB 3.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/13.9 MB 3.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/13.9 MB 4.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/13.9 MB 6.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.3/13.9 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/13.9 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.1/13.9 MB 18.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.0/13.9 MB 21.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.9/13.9 MB 24.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.8/13.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/13.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 38.6 MB/s eta 0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.7/116.7 kB ? eta 0:00:00\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.6/632.6 kB 20.1 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.7/1.7 MB 36.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 37.0 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.0/12.8 MB 43.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.1/12.8 MB 43.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.1/12.8 MB 43.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.5/12.8 MB 43.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.8 MB 42.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.4/12.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 36.4 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.17.4-py3-none-any.whl (46 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.0/6.3 MB 43.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 44.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 44.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 40.1 MB/s eta 0:00:00\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 243.4/243.4 kB ? eta 0:00:00\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.7/61.7 kB ? eta 0:00:00\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.6/44.6 kB ? eta 0:00:00\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading marisa_trie-1.3.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.6/138.6 kB ? eta 0:00:00\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.3/87.3 kB ? eta 0:00:00\n",
      "Downloading wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, typing-extensions, tqdm, spacy-loggers, spacy-legacy, shellingham, numpy, murmurhash, mdurl, marisa-trie, cloudpathlib, click, catalogue, annotated-types, typing-inspection, srsly, smart-open, pydantic-core, preshed, markdown-it-py, language-data, blis, rich, pydantic, langcodes, typer, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 click-8.2.1 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 numpy-2.3.2 preshed-3.0.10 pydantic-2.11.7 pydantic-core-2.33.2 rich-14.1.0 shellingham-1.5.4 smart-open-7.3.1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 tqdm-4.67.1 typer-0.17.4 typing-extensions-4.15.0 typing-inspection-0.4.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.2 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee765ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import spacy.cli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e41d1b",
   "metadata": {},
   "source": [
    "One-time use only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02508fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054be689",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c809600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =  nlp(\"Apple is looking at buying U.K. startup for $1 billion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db976883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens generated: from the sample: \n",
      "Apple - PROPN - nsubj\n",
      "is - AUX - aux\n",
      "looking - VERB - ROOT\n",
      "at - ADP - prep\n",
      "buying - VERB - pcomp\n",
      "U.K. - PROPN - nsubj\n",
      "startup - VERB - ccomp\n",
      "for - ADP - prep\n",
      "$ - SYM - quantmod\n",
      "1 - NUM - compound\n",
      "billion - NUM - pobj\n",
      ". - PUNCT - punct\n",
      "\n",
      "Extracting Named Entities NERs from sample:\n",
      "Apple -> ORG\n",
      "U.K. -> GPE\n",
      "$1 billion -> MONEY\n",
      "\n",
      "Dependency Parsing from sample:\n",
      "Apple --> looking --> nsubj\n",
      "is --> looking --> aux\n",
      "looking --> looking --> ROOT\n",
      "at --> looking --> prep\n",
      "buying --> at --> pcomp\n",
      "U.K. --> startup --> nsubj\n",
      "startup --> buying --> ccomp\n",
      "for --> startup --> prep\n",
      "$ --> billion --> quantmod\n",
      "1 --> billion --> compound\n",
      "billion --> for --> pobj\n",
      ". --> looking --> punct\n",
      "\n",
      "Lemmatization from sample:\n",
      "Apple --> Apple\n",
      "is --> be\n",
      "looking --> look\n",
      "at --> at\n",
      "buying --> buy\n",
      "U.K. --> U.K.\n",
      "startup --> startup\n",
      "for --> for\n",
      "$ --> $\n",
      "1 --> 1\n",
      "billion --> billion\n",
      ". --> .\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "print(\"Tokens generated: from the sample: \")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} - {token.pos_} - {token.dep_}\")\n",
    "\n",
    "#Named Entity Recognition\n",
    "print(\"\\nExtracting Named Entities NERs from sample:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n",
    "\n",
    "#Dependency Parsing\n",
    "print(\"\\nDependency Parsing from sample:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} --> {token.head.text} --> {token.dep_}\")\n",
    "\n",
    "#Lemmatization (root word extraction)\n",
    "print(\"\\nLemmatization from sample:\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} --> {token.lemma_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97480f8a",
   "metadata": {},
   "source": [
    "en_core_web_md Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07e53863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09dbb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_md = spacy.load(\"en_core_web_md\")\n",
    "print = (\"Model 'en_core_web_md' loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55605a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity between two documents:\n",
      "0.8661232590675354\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp_md(\"Apple is launching its new iphone model in New York this week.\")\n",
    "doc2 = nlp_md(\"Iphone 8 is the product of Apple.\")\n",
    "\n",
    "del print\n",
    "\n",
    "print(\"\\nSimilarity between two documents:\")\n",
    "print(doc1.similarity(doc2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d54f6e",
   "metadata": {},
   "source": [
    "Custom Pipeline Component using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7da40e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Has Exclamation:  True\n",
      "\n",
      "Verbs in the sentence:  ['building']\n",
      "['Tesla', 'is', 'building', 'a', 'giga', 'factory', 'in', 'Berlin', '!']\n",
      "[('Tesla', 'ORG'), ('Berlin', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "from spacy.tokens import Doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "if not Doc.has_extension(\"has_exclamation\"):\n",
    "    Doc.set_extension(\"has_exclamation\", default=False)\n",
    "\n",
    "@spacy.Language.component(\"exclamation_flager\")\n",
    "def exlamation_flager_function(doc):\n",
    "    doc._.has_exclamation = \"!\" in doc.text \n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"exclamation_flager\", last=True)\n",
    "\n",
    "doc = nlp(\"Wow! This is Amazing!!!\")\n",
    "print(\"\\nHas Exclamation: \", doc._.has_exclamation)\n",
    "\n",
    "@spacy.Language.component(\"custom_logic\")\n",
    "def custom_logic(doc):\n",
    "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
    "    print(\"\\nVerbs in the sentence: \", verbs)\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"custom_logic\", last = True)\n",
    "\n",
    "text = \"Tesla is building a giga factory in Berlin!\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print([token.text for token in doc])\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d791e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
